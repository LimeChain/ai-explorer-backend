# Environment variables for AI Explorer Backend
# Copy this file and update with your actual values

# Environment settings
ENVIRONMENT=development
LOG_LEVEL=INFO

# LLM
LLM_PROVIDER=openai
LLM_MODEL=gpt-4.1-mini
LLM_API_KEY=openai-api-key-placeholder
LLM_INPUT_COST_PER_TOKEN=0.0000004
LLM_OUTPUT_COST_PER_TOKEN=0.0000016

# MCP Servers
MCP_ENDPOINT=http://localhost:8001/mcp/
# MCP_ENDPOINT=http://mcp-server:8001/mcp/ # This is for Docker, if you are going to run locally, change to http://localhost:8001/mcp/

# Database / Vector Store
DATABASE_URL=postgresql+psycopg://ai_explorer:ai_explorer@localhost:5432/ai_explorer
COLLECTION_NAME=sdk_methods

# Redis
REDIS_URL=redis://localhost:6379/0

# Rate Limiting
RATE_LIMIT_MAX_REQUESTS=5
RATE_LIMIT_WINDOW_SECONDS=60
GLOBAL_RATE_LIMIT_MAX_REQUESTS=100
GLOBAL_RATE_LIMIT_WINDOW_SECONDS=60

# Cost Control
PER_USER_COST_LIMIT=10 # USD cost limit
PER_USER_PERIOD_SECONDS=86400 # 86400 seconds = 24 hours
GLOBAL_COST_LIMIT=100 # USD cost limit
GLOBAL_COST_PERIOD_SECONDS=31536000 # 31536000 seconds = 365 days

# LangGraph
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=<langsmith-api-key>
LANGSMITH_PROJECT=<project-name>

# CORS
ALLOWED_ORIGINS=["*"]
